{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
      "Path to dataset files: C:\\Users\\HONOR\\.cache\\kagglehub\\datasets\\uciml\\sms-spam-collection-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uciml/sms-spam-collection-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "data = data[['v1', 'v2']] # Оставляем только два столбца: 'v1' (метка класса) и 'v2' (сообщение)\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Беру из датасета первые 5560 строк, чтобы обучить модель (данные будут использоваться для обучения \n",
    "# и тестирования 75% на 25%), остальные строки датасета оставлю для наглядного тестирования\n",
    "\n",
    "# Выделяем первые 5560 строк для обучения и тестирования модели\n",
    "train_test_data = data.iloc[:5560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts after oversampling:\n",
      " v1\n",
      "ham     4815\n",
      "spam    4815\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Определяем признаки (X) и метки классов (y)\n",
    "X = train_test_data['v2'].values.reshape(-1, 1) # Преобразуем столбец сообщений в форму массива с одним признаком\n",
    "y = train_test_data['v1']      # Метки классов (spam или ham)                   \n",
    "\n",
    "# Применяем oversampling, чтобы сбалансировать классы\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Создаем новый DataFrame с сбалансированными данными\n",
    "balanced_data = pd.DataFrame(X_resampled, columns=['v2'])\n",
    "balanced_data['v1'] = y_resampled\n",
    "\n",
    "print(\"Class counts after oversampling:\\n\", balanced_data['v1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONOR\\AppData\\Local\\Temp\\ipykernel_11136\\2715127840.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_test_data['v1'] = train_test_data['v1'].astype(str)\n",
      "C:\\Users\\HONOR\\AppData\\Local\\Temp\\ipykernel_11136\\2715127840.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_test_data['v1'] = train_test_data['v1'].map({'ham': 0, 'spam': 1})\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем столбец меток классов ('v1') в строковый формат, чтобы избежать ошибок при дальнейших преобразованиях\n",
    "train_test_data['v1'] = train_test_data['v1'].astype(str)\n",
    "# Заменяем текстовые метки классов: 'ham' (не спам) преобразуется в 0, а 'spam' в 1\n",
    "train_test_data['v1'] = train_test_data['v1'].map({'ham': 0, 'spam': 1})\n",
    "# Удаляем строки, где в столбцах 'v1' или 'v2' имеются пропущенные значения\n",
    "train_test_data = train_test_data.dropna(subset=['v1', 'v2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HONOR\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.5984 - loss: 0.5930 - val_accuracy: 0.8686 - val_loss: 0.4346\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8727 - loss: 0.3762 - val_accuracy: 0.8686 - val_loss: 0.4806\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.8691 - loss: 0.3454 - val_accuracy: 0.8686 - val_loss: 0.4132\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.8650 - loss: 0.2727 - val_accuracy: 0.9645 - val_loss: 0.3420\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.9360 - loss: 0.1885 - val_accuracy: 0.9760 - val_loss: 0.2789\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.9830 - loss: 0.1158 - val_accuracy: 0.9808 - val_loss: 0.2305\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.9879 - loss: 0.0785 - val_accuracy: 0.9837 - val_loss: 0.2030\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.9873 - loss: 0.0637 - val_accuracy: 0.9856 - val_loss: 0.1792\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.9934 - loss: 0.0421 - val_accuracy: 0.9808 - val_loss: 0.1553\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.9923 - loss: 0.0420 - val_accuracy: 0.9818 - val_loss: 0.1414\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step\n",
      "Accuracy: 0.9841726618705036\n",
      "F1-Score: 0.9408602150537635\n",
      "ROC-AUC: 0.9917724028548771\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем текстовые данные ('v2') в список строк для дальнейшей обработки\n",
    "X_text = train_test_data['v2'].values.tolist()\n",
    "y = train_test_data['v1'].values # Преобразуем метки классов ('v1') в массив\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки \n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.25, random_state=42\n",
    ")\n",
    "# Создаем объект Tokenizer для преобразования текстов в числовые последовательности\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_text)# Строим словарь токенов на обучающей выборке\n",
    "\n",
    "# Преобразуем тексты в числовые последовательности\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "\n",
    "max_length = 200\n",
    "# Применяем дополнение (padding) последовательностей до заданной длины\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Создаем модель нейронной сети\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_length))\n",
    "\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Обучаем модель на обучающей выборке с разделением на валидационную выборку \n",
    "history = model.fit(\n",
    "    X_train_padded,\n",
    "    y_train,\n",
    "    validation_split=0.25,\n",
    "    epochs=10, \n",
    "    batch_size=512\n",
    ")\n",
    "\n",
    "# Получаем предсказания на тестовой выборке\n",
    "predictions = model.predict(X_test_padded)\n",
    "\n",
    "# Преобразуем вероятности в бинарные метки (0 или 1) с порогом 0.5\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicted_labels))\n",
    "print(\"F1-Score:\", f1_score(y_test, predicted_labels))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтобы протестировать модель возьму столбцы датасета, которые не были использованы в обучении модели. Выделенные строки относятся к SPAM.\n",
    "\n",
    "1. No. I meant the calculation is the same. That  &lt;#&gt; units at  &lt;#&gt; . This school is really expensive. Have you started practicing your accent.\n",
    "2. Because its important. And have you decided if you are doing 4years of dental school or if you'll just do the nmde exam.\n",
    "3. \"Sorry, I'll call later\"\n",
    "4. if you aren't here in the next  &lt;#&gt;  hours imma flip my shit\n",
    "5. Anything lor. Juz both of us lor.\n",
    "6. Get me out of this dump heap. My mom decided to come to lowes. BORING.\n",
    "7. Ok lor... Sony ericsson salesman... I ask shuhui then she say quite gd 2 use so i considering...\n",
    "8. Ard 6 like dat lor.\n",
    "9. Why don't you wait 'til at least wednesday to see if you get your .\n",
    "10. Huh y lei...\n",
    "\n",
    "**11. \"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\"**\n",
    "\n",
    "\n",
    "**12. \"This is the 2nd time we have tried 2 contact u. U have won the �750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.\"**\n",
    "\n",
    "13. Will �_ b going to esplanade fr home?\n",
    "14. \"Pity, * was in mood for that. So...any other suggestions?\"\n",
    "15. The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\n",
    "16. Rofl. Its true to its name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Текст</th>\n",
       "      <th>Предсказание (Spam=1, Ham=0)</th>\n",
       "      <th>Вероятность (Spam)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Because its important. And have you decided if...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you aren't here in the next &lt;#&gt; hours imma ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Will �_ b going to esplanade fr home?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'Pity, * was in mood for that. So...any other ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Текст  \\\n",
       "0   No. I meant the calculation is the same. That ...   \n",
       "1   Because its important. And have you decided if...   \n",
       "2                              Sorry, I'll call later   \n",
       "3   if you aren't here in the next <#> hours imma ...   \n",
       "4                   Anything lor. Juz both of us lor.   \n",
       "5   Get me out of this dump heap. My mom decided t...   \n",
       "6   Ok lor... Sony ericsson salesman... I ask shuh...   \n",
       "7                                 Ard 6 like dat lor.   \n",
       "8   Why don't you wait 'til at least wednesday to ...   \n",
       "9                                        Huh y lei...   \n",
       "10  REMINDER FROM O2: To get 2.50 pounds free call...   \n",
       "11  This is the 2nd time we have tried 2 contact u...   \n",
       "12              Will �_ b going to esplanade fr home?   \n",
       "13  'Pity, * was in mood for that. So...any other ...   \n",
       "14  The guy did some bitching but I acted like i'd...   \n",
       "15                         Rofl. Its true to its name   \n",
       "\n",
       "    Предсказание (Spam=1, Ham=0)  Вероятность (Spam)  \n",
       "0                              0            0.141712  \n",
       "1                              0            0.141731  \n",
       "2                              0            0.121487  \n",
       "3                              0            0.126106  \n",
       "4                              0            0.119861  \n",
       "5                              0            0.132995  \n",
       "6                              0            0.129522  \n",
       "7                              0            0.122643  \n",
       "8                              0            0.139860  \n",
       "9                              0            0.117833  \n",
       "10                             1            0.937005  \n",
       "11                             1            0.932061  \n",
       "12                             0            0.125116  \n",
       "13                             0            0.119489  \n",
       "14                             0            0.135420  \n",
       "15                             0            0.128620  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Пример новых данных\n",
    "new_data = [\n",
    "    \"No. I meant the calculation is the same. That <#> units at <#>. This school is really expensive. Have you started practicing your accent. Because it's important. And have you decided if you are doing 4 years of dental school or if you'll just do the nmde exam.\",\n",
    "    \"Because its important. And have you decided if you are doing 4years of dental school or if you'll just do the nmde exam.\",\n",
    "    \"Sorry, I'll call later\",\n",
    "    \"if you aren't here in the next <#> hours imma flip my shit\",\n",
    "    \"Anything lor. Juz both of us lor.\",\n",
    "    \"Get me out of this dump heap. My mom decided to come to lowes. BORING.\",\n",
    "    \"Ok lor... Sony ericsson salesman... I ask shuhui then she say quite gd 2 use so i considering...\",\n",
    "    \"Ard 6 like dat lor.\",\n",
    "    \"Why don't you wait 'til at least wednesday to see if you get your .\",\n",
    "    \"Huh y lei...\",\n",
    "    \"REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode\",\n",
    "    \"This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. To claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.\",\n",
    "    \"Will �_ b going to esplanade fr home?\",\n",
    "    \"'Pity, * was in mood for that. So...any other suggestions?'\",\n",
    "    \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\",\n",
    "    \"Rofl. Its true to its name\"\n",
    "]\n",
    "\n",
    "# Токенизируем новые данные (используем обученный токенайзер)\n",
    "new_sequences = tokenizer.texts_to_sequences(new_data)\n",
    "\n",
    "# Дополняем последовательности до max_length\n",
    "new_padded = pad_sequences(new_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Подаем данные в модель для предсказания\n",
    "predictions = model.predict(new_padded)\n",
    "\n",
    "# Интерпретируем результаты: если вероятность > 0.5, классифицируем как spam (1), иначе как ham (0)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Объединяем текст с предсказаниями\n",
    "results = pd.DataFrame({\n",
    "    \"Текст\": new_data,\n",
    "    \"Предсказание (Spam=1, Ham=0)\": predicted_labels.flatten(),\n",
    "    \"Вероятность (Spam)\": predictions.flatten()\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Выводим результаты\n",
    "# Печать всей таблицы как строки\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Из тестирования видно, что модель определила все сообщения, которые пренадлежат к spam и ham"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
